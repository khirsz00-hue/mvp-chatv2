import { getOpenAIClient } from '@/lib/openai'
import { HAT_PROMPTS } from '../prompts/hats'
import { Decision, DecisionOption, HatColor, DecisionSynthesis } from '../types'

export class DecisionAIService {
  // Simple template replacement (no external dependencies needed)
  private static replaceTemplate(
    template: string,
    data: { title: string; description: string; options?: DecisionOption[]; isStart?: boolean }
  ): string {
    let result = template
    result = result.replace(/\{\{title\}\}/g, data.title)
    result = result.replace(/\{\{description\}\}/g, data.description)

    // Handle conditional blocks
    if (data.options && data.options.length > 0) {
      const optionsText = data.options
        .map(opt => `- ${opt.title}: ${opt.description || '(bez opisu)'}`)
        .join('\n')
      result = result.replace(
        /\{\{#if options\}\}[\s\S]*?\{\{\/if\}\}/g,
        `Opcje do rozwaÅ¼enia:\n${optionsText}`
      )
    } else {
      result = result.replace(/\{\{#if options\}\}[\s\S]*?\{\{\/if\}\}/g, '')
    }

    // Handle isStart conditional
    if (data.isStart !== undefined) {
      const startText = data.isStart
        ? 'jasno zdefiniowaÄ‡ problem i kontekst tej decyzji'
        : 'stworzyÄ‡ syntetyczne podsumowanie i plan dziaÅ‚aÅ„ na podstawie wszystkich perspektyw'
      result = result.replace(/\{\{#if isStart\}\}.*?\{\{else\}\}.*?\{\{\/if\}\}/g, startText)
    }

    return result
  }

  // Analyze decision from a specific hat perspective
  static async analyzeWithHat(
    decision: Decision,
    options: DecisionOption[],
    hatColor: HatColor,
    isStart: boolean = false
  ): Promise<string> {
    const hatPrompt = HAT_PROMPTS[hatColor]
    if (!hatPrompt) {
      throw new Error(`Invalid hat color: ${hatColor}`)
    }

    const userPrompt = this.replaceTemplate(hatPrompt.userPromptTemplate, {
      title: decision.title,
      description: decision.description,
      options,
      isStart
    })

    const openai = getOpenAIClient()

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: hatPrompt.systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.7,
      max_tokens: 1000
    })

    return completion.choices[0].message.content || ''
  }

  // Generate synthesis from all hat analyses
  static async generateSynthesis(
    decision: Decision,
    events: Array<{ hat_color: string; ai_response?: string | null; content: string }>
  ): Promise<DecisionSynthesis> {
    const hatAnalyses: Record<string, string> = {}

    events.forEach(event => {
      if (event.ai_response) {
        if (!hatAnalyses[event.hat_color]) {
          hatAnalyses[event.hat_color] = event.ai_response
        }
      }
    })

    const systemPrompt = `JesteÅ› doÅ›wiadczonym facylitatorem metody 6 kapeluszy myÅ›lowych.
Twoim zadaniem jest stworzyÄ‡ kompleksowe podsumowanie analizy decyzji z wszystkich perspektyw.

Przeanalizuj wyniki z kaÅ¼dego kapelusza i stwÃ³rz:
1. ListÄ™ kluczowych faktÃ³w
2. ListÄ™ emocji i intuicji
3. ListÄ™ ryzyk i zagroÅ¼eÅ„
4. ListÄ™ korzyÅ›ci i szans
5. ListÄ™ pomysÅ‚Ã³w i rozwiÄ…zaÅ„
6. Konkretny plan dziaÅ‚aÅ„
7. RekomendacjÄ™

OdpowiedÅº zwrÃ³Ä‡ w formacie JSON z kluczami: facts, emotions, risks, benefits, ideas, action_plan, recommendation.
KaÅ¼dy klucz (oprÃ³cz action_plan i recommendation) powinien byÄ‡ tablicÄ… stringÃ³w. action_plan i recommendation to pojedyncze stringi.`

    const userPrompt = `Decyzja: ${decision.title}

Analiza z poszczegÃ³lnych perspektyw:

ðŸ”µ Start (BÅ‚Ä™kitny kapelusz):
${hatAnalyses['blue'] || 'Brak analizy'}

âšª Fakty (BiaÅ‚y kapelusz):
${hatAnalyses['white'] || 'Brak analizy'}

ðŸ”´ Emocje (Czerwony kapelusz):
${hatAnalyses['red'] || 'Brak analizy'}

âš« Ryzyka (Czarny kapelusz):
${hatAnalyses['black'] || 'Brak analizy'}

ðŸŸ¡ KorzyÅ›ci (Å»Ã³Å‚ty kapelusz):
${hatAnalyses['yellow'] || 'Brak analizy'}

ðŸŸ¢ PomysÅ‚y (Zielony kapelusz):
${hatAnalyses['green'] || 'Brak analizy'}

StwÃ³rz kompleksowe podsumowanie i rekomendacjÄ™.`

    const openai = getOpenAIClient()

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.7,
      max_tokens: 2000,
      response_format: { type: 'json_object' }
    })

    const responseText = completion.choices[0].message.content || '{}'
    const parsed = JSON.parse(responseText)

    return {
      decision_id: decision.id,
      facts: Array.isArray(parsed.facts) ? parsed.facts : [],
      emotions: Array.isArray(parsed.emotions) ? parsed.emotions : [],
      risks: Array.isArray(parsed.risks) ? parsed.risks : [],
      benefits: Array.isArray(parsed.benefits) ? parsed.benefits : [],
      ideas: Array.isArray(parsed.ideas) ? parsed.ideas : [],
      action_plan: parsed.action_plan || '',
      recommendation: parsed.recommendation || '',
      created_at: new Date().toISOString()
    }
  }
}
