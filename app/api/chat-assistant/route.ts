/**
 * Chat Assistant API Endpoint
 * Provides AI-powered chat with access to all user data
 */

import { NextRequest, NextResponse } from 'next/server'
import { createAuthenticatedSupabaseClient, getAuthenticatedUser } from '@/lib/supabaseAuth'
import { 
  fetchChatContext, 
  formatMinimalContextForAI,
  findFreeTimeSlots,
  getOverdueTasks,
  getTodayTasks,
  getSimplestTasks,
  TaskContext
} from '@/lib/services/chatContextService'
import OpenAI from 'openai'

// Initialize OpenAI client only if API key is available
const openai = process.env.OPENAI_API_KEY
  ? new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    })
  : null

interface ChatMessage {
  role: 'user' | 'assistant' | 'system'
  content: string
}

interface ChatRequest {
  message: string
  conversationHistory?: ChatMessage[]
}

interface StructuredResponse {
  type: 'tasks' | 'meeting_slots' | 'text'
  text: string
  tasks?: TaskContext[]
  slots?: Array<{ time: string; duration: number; energyLevel?: number }>
  footer?: string
}

const SYSTEM_PROMPT = `Jeste≈õ asystentem ADHD. Komunikuj siƒô zgodnie z tymi zasadami:

STYL ODPOWIEDZI:
- Maksymalnie 2-3 kr√≥tkie zdania
- U≈ºywaj wypunktowa≈Ñ i emoji (‚úÖ ‚è∞ üéØ ‚ö° üí™ ‚ö†Ô∏è)
- ZERO poucze≈Ñ typu "powiniene≈õ", "warto by≈Çoby", "sugerujƒô"
- Tylko konkretne fakty i liczby
- Akcent na TO CO TERAZ, nie na przysz≈Ço≈õƒá

PRZYK≈ÅADY DOBRYCH ODPOWIEDZI:

User: "Kiedy najlepszy czas na spotkanie?"
AI: "‚úÖ Najbli≈ºsze wolne:
‚Ä¢ ≈öroda 15:00-16:00 (energia 8/10)
‚Ä¢ Czwartek 10:00-11:30 (najlepszy focus)
Kt√≥ra opcja?"

User: "Jakie mam zadania na dzi≈õ?"
AI: "üéØ Dzi≈õ masz 6 zada≈Ñ (3h 20min):
[Poka≈º jako karty - system to obs≈Çu≈ºy]
Reszta (3) ma ni≈ºszy priorytet."

User: "Nie mogƒô siƒô skupiƒá"
AI: "üí™ Rozumiem. Wybierz JEDNO:
[Poka≈º najprostsze zadania jako karty]
Od kt√≥rego zaczynasz?"

User: "Jakie mam przeterminowane?"
AI: "‚ö†Ô∏è 4 przeterminowane (≈ÇƒÖcznie 2h 15min):
[Poka≈º jako karty]
Kt√≥re jako pierwsze?"

ZAKAZANE FORMU≈ÅOWANIA:
‚ùå "Powiniene≈õ zaczƒÖƒá od..."
‚ùå "Sugerowa≈Çbym, aby..."
‚ùå "Warto by≈Çoby..."
‚ùå "Proponujƒô nastƒôpujƒÖce kroki..."
‚ùå D≈Çugie paragrafy

DOZWOLONE:
‚úÖ "Masz X zada≈Ñ"
‚úÖ "Najlepszy czas: ..."
‚úÖ "Od kt√≥rego zaczynasz?"
‚úÖ Wypunktowania
‚úÖ Karty zada≈Ñ (automatycznie dodane przez system)`

export async function POST(request: NextRequest) {
  try {
    console.log('üîç [Chat Assistant API] Starting request')

    // Authenticate user
    const supabase = await createAuthenticatedSupabaseClient()
    const user = await getAuthenticatedUser(supabase)

    if (!user) {
      console.error('‚ùå [Chat Assistant API] Unauthorized - no user found')
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    console.log(`‚úÖ [Chat Assistant API] User authenticated: ${user.id}`)

    // Check if OpenAI is configured
    if (!openai) {
      console.error('‚ùå [Chat Assistant API] OpenAI API key not configured')
      return NextResponse.json(
        { error: 'Chat assistant is not configured. Please contact administrator.' },
        { status: 503 }
      )
    }

    // Parse request body
    const body: ChatRequest = await request.json()
    const { message, conversationHistory = [] } = body

    // Validate message
    if (!message || message.trim().length === 0) {
      return NextResponse.json(
        { error: 'Message is required' },
        { status: 400 }
      )
    }

    if (message.length > 500) {
      return NextResponse.json(
        { error: 'Message too long (max 500 characters)' },
        { status: 400 }
      )
    }

    console.log(`üîç [Chat Assistant API] Fetching user context for user: ${user.id}`)

    // Fetch user context
    const context = await fetchChatContext(supabase, user.id)
    const contextString = formatMinimalContextForAI(context)

    console.log(`‚úÖ [Chat Assistant API] Context fetched:
- Tasks today: ${context.tasks.today.length}
- Overdue: ${context.tasks.overdue.length}
- Journal entries: ${context.journal.recent.length}
- Active decisions: ${context.decisions.active.length}`)

    // Detect user intent and prepare structured response if needed
    const userMessageLower = message.toLowerCase()
    let structuredResponse: StructuredResponse | null = null

    // Intent: Meeting time questions
    if (
      userMessageLower.includes('spotkanie') ||
      userMessageLower.includes('wolny') ||
      userMessageLower.includes('um√≥wiƒá') ||
      (userMessageLower.includes('kiedy') && (userMessageLower.includes('czas') || userMessageLower.includes('slot')))
    ) {
      const slots = await findFreeTimeSlots(supabase, user.id)
      if (slots.length > 0) {
        structuredResponse = {
          type: 'meeting_slots',
          text: `‚úÖ Najbli≈ºsze wolne sloty:`,
          slots: slots
        }
      }
    }
    // Intent: Tasks today
    else if (
      (userMessageLower.includes('zadania') || userMessageLower.includes('task') || userMessageLower.includes('co')) &&
      (userMessageLower.includes('dzi≈õ') || userMessageLower.includes('dzisiaj') || userMessageLower.includes('today'))
    ) {
      const tasks = await getTodayTasks(supabase, user.id, 5)
      const totalTime = tasks.reduce((sum, t) => sum + t.estimate_min, 0)
      const totalCount = context.tasks.today.length
      structuredResponse = {
        type: 'tasks',
        text: `üéØ Dzi≈õ masz ${totalCount} ${totalCount === 1 ? 'zadanie' : totalCount < 5 ? 'zadania' : 'zada≈Ñ'} (${Math.floor(totalTime / 60)}h ${totalTime % 60}min):`,
        tasks: tasks,
        footer: totalCount > 5 ? `Reszta (${totalCount - 5}) ma ni≈ºszy priorytet.` : undefined
      }
    }
    // Intent: Overdue tasks
    else if (
      (userMessageLower.includes('przeterminowane') || userMessageLower.includes('overdue') || userMessageLower.includes('sp√≥≈∫nione')) ||
      (userMessageLower.includes('jakie') && userMessageLower.includes('zaleg≈Çe'))
    ) {
      const tasks = await getOverdueTasks(supabase, user.id, 5)
      const totalTime = tasks.reduce((sum, t) => sum + t.estimate_min, 0)
      structuredResponse = {
        type: 'tasks',
        text: `‚ö†Ô∏è ${tasks.length} ${tasks.length === 1 ? 'przeterminowane' : 'przeterminowanych'} (≈ÇƒÖcznie ${Math.floor(totalTime / 60)}h ${totalTime % 60}min):`,
        tasks: tasks,
        footer: 'Kt√≥re jako pierwsze?'
      }
    }
    // Intent: Emotional support / overwhelmed
    else if (
      userMessageLower.includes('nie mogƒô siƒô skupiƒá') ||
      userMessageLower.includes('nie mogƒô siƒô ogarnƒÖƒá') ||
      userMessageLower.includes('przyt≈Çacza') ||
      userMessageLower.includes('za du≈ºo') ||
      userMessageLower.includes('overwhelmed')
    ) {
      const tasks = await getSimplestTasks(supabase, user.id, 3)
      structuredResponse = {
        type: 'tasks',
        text: `üí™ Rozumiem. Wybierz JEDNO:`,
        tasks: tasks,
        footer: 'Od kt√≥rego zaczynasz?'
      }
    }

    // If we have structured response, return it immediately without calling OpenAI
    if (structuredResponse) {
      console.log(`‚úÖ [Chat Assistant API] Returning structured response: ${structuredResponse.type}`)
      
      return NextResponse.json(structuredResponse)
    }

    // Build messages for OpenAI
    const messages: ChatMessage[] = [
      {
        role: 'system',
        content: SYSTEM_PROMPT,
      },
      {
        role: 'system',
        content: `DANE U≈ªYTKOWNIKA:\n${contextString}`,
      },
      ...conversationHistory.slice(-6), // Keep last 6 messages (3 pairs) for context
      {
        role: 'user',
        content: message,
      },
    ]

    console.log(`üîç [Chat Assistant API] Calling OpenAI with ${messages.length} messages`)

    // Call OpenAI with streaming
    const stream = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: messages as any,
      temperature: 0.3,
      max_tokens: 150,
      stream: true,
    })

    console.log(`‚úÖ [Chat Assistant API] Streaming response started`)

    // Create SSE (Server-Sent Events) response
    const encoder = new TextEncoder()
    const readable = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of stream) {
            const text = chunk.choices[0]?.delta?.content
            if (text) {
              const data = `data: ${JSON.stringify({ text })}\n\n`
              controller.enqueue(encoder.encode(data))
            }
          }
          controller.enqueue(encoder.encode('data: [DONE]\n\n'))
        } catch (err) {
          console.error('‚ùå [Chat Assistant API] Streaming error:', err)
          controller.error(err)
        } finally {
          controller.close()
        }
      }
    })

    return new Response(readable, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      }
    })
  } catch (error: any) {
    console.error('‚ùå [Chat Assistant API] Error:', error)
    
    // Handle OpenAI API errors
    if (error?.status === 429) {
      return NextResponse.json(
        { error: 'Rate limit exceeded. Please try again later.' },
        { status: 429 }
      )
    }

    if (error?.status === 401) {
      return NextResponse.json(
        { error: 'OpenAI API key invalid or missing' },
        { status: 500 }
      )
    }

    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    )
  }
}
