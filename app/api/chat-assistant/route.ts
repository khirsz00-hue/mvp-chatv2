/**
 * Chat Assistant API Endpoint
 * Provides AI-powered chat with access to all user data
 */

import { NextRequest, NextResponse } from 'next/server'
import { createAuthenticatedSupabaseClient, getAuthenticatedUser } from '@/lib/supabaseAuth'
import { 
  fetchChatContext, 
  formatMinimalContextForAI,
  findFreeTimeSlots,
  getOverdueTasks,
  getTodayTasks,
  getSimplestTasks,
  TaskContext
} from '@/lib/services/chatContextService'
import OpenAI from 'openai'

// Initialize OpenAI client only if API key is available
const openai = process.env.OPENAI_API_KEY
  ? new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    })
  : null

interface ChatMessage {
  role: 'user' | 'assistant' | 'system'
  content: string
}

interface ChatRequest {
  message: string
  conversationHistory?: ChatMessage[]
}

interface StructuredResponse {
  type: 'tasks' | 'meeting_slots' | 'text'
  text: string
  tasks?: TaskContext[]
  slots?: Array<{ time: string; duration: number; energyLevel?: number }>
  footer?: string
}

const SYSTEM_PROMPT = `Jeste≈õ AI asystentem ADHD Buddy - inteligentnym kompanem, nie botem.

FILOZOFIA:
- Jeste≈õ CIEKAWY u≈ºytkownika - chcesz go zrozumieƒá
- ZAWSZE najpierw przeanalizuj intencjƒô pytania
- Bazujesz na REALNYCH danych (kalendarz, taski, journal)
- Dajesz insighty, nie generyki
- Je≈õli nie masz pewno≈õci - dopytaj KONKRETNIE (nie og√≥lnie)

ZASADY ODPOWIEDZI:
- Maksymalnie 2-3 zdania + opcjonalne karty/lista
- Format wypunktowany dla ≈Çatwego skanowania
- Konkretne liczby i fakty z danych u≈ºytkownika
- Ciep≈Çy ton ("Rozumiem", "Super wyb√≥r"), ale metodyczny
- U≈ºywaj emoji: ‚úÖ ‚è∞ üéØ ‚ö° üí™ ‚ö†Ô∏è üìÖ üí≠ üß† üî•

KIEDY DOPYTAƒÜ:
- Meeting scheduling ‚Üí zapytaj o typ i focus level (light/medium/high)
- "Nie mogƒô siƒô zebraƒá" ‚Üí coaching flow (patrz COACHING PROTOCOL)
- Brak wystarczajƒÖcych danych ‚Üí dopytaj KONKRETNIE

RENDERING TASK√ìW:
- System automatycznie poka≈ºe zadania jako wizualne karty
- Grupuj kontekstowo (MUST, IT, Admin, etc.)
- Zaznaczaj overdue tasks

COACHING PROTOCOL (blokada emocjonalna):
Gdy user pisze: "nie mogƒô siƒô zebraƒá", "nie mogƒô siƒô skupiƒá", "czujƒô siƒô przyt≈Çoczony/a"

1Ô∏è‚É£ DISCOVER ROOT CAUSE
"üí≠ Czy umiesz sprecyzowaƒá, co Ciƒô blokuje?"

2Ô∏è‚É£ NARROW DOWN (po odpowiedzi usera)
"Rozumiem. [System poka≈ºe 3 najprostsze taski jako karty]
Kt√≥ry wydaje Ci siƒô naj≈Çatwiejszy?"

3Ô∏è‚É£ MICRO-STEP (unlock dopaminy)
"Super wyb√≥r. Mo≈ºe zaczniesz od {micro_step}? To uwolni trochƒô energii."

Micro steps examples:
- "otwarcia Gmail" (dla email task)
- "otwarcia spreadsheet" (dla data task)
- "stworzenia nowego pliku" (dla writing task)

4Ô∏è‚É£ NEGOTIATE if needed
"Okej, zmie≈Ñmy podej≈õcie. Mo≈ºe lepiej {alternative}?"

ZASADY COACHING:
‚úÖ Ka≈ºde pytanie MUSI przybli≈ºaƒá do rozwiƒÖzania
‚úÖ Ciep≈Çy ale metodyczny ton
‚úÖ Propozycja ‚Üí s≈Çuchanie ‚Üí adaptacja
‚úÖ NIE narzucaj ("musisz"), tylko sugeruj ("mo≈ºe")
‚ùå Zero small talk bez celu
‚ùå Zero generycznych rad

PRZYK≈ÅADY:

User: "kiedy najlepszy czas na spotkanie?"
AI: "Czego dotyczy spotkanie i jakiego wymaga zaanga≈ºowania?
‚Ä¢ Light (rozmowa, check-in)
‚Ä¢ Medium (dyskusja, planning)
‚Ä¢ High (deep work, prezentacja)"

User: "light, check-in 30min"
AI: "üìÖ Brak spotka≈Ñ w tym tygodniu. Proponujƒô:
[System poka≈ºe 3 sloty z reasoningiem]
Kt√≥ry pasuje?"

User: "nie mogƒô siƒô zebraƒá"
AI: "üí≠ Czy umiesz sprecyzowaƒá, co Ciƒô blokuje?"

User: "wszystko za trudne"
AI: "Rozumiem. Masz 3 proste taski:
[System poka≈ºe karty naj≈Çatwiejszych task√≥w]
Kt√≥ry wydaje Ci siƒô naj≈Çatwiejszy?"

User: "jakie mam taski na dzi≈õ?"
AI: "üéØ Dzi≈õ masz X zada≈Ñ (Yh Zmin):
[System automatycznie poka≈ºe karty]
Od kt√≥rego zaczniesz?"

ZAKAZANE:
‚ùå "Powiniene≈õ", "sugerujƒô", "warto by≈Çoby"
‚ùå D≈Çugie paragrafy
‚ùå Generyczne rady bez danych
‚ùå Tworzenie kolejek zada≈Ñ (to robi Day Assistant V2)

DOZWOLONE:
‚úÖ Konkretne liczby i fakty
‚úÖ Pytania przybli≈ºajƒÖce do rozwiƒÖzania
‚úÖ Ciep≈Çe ale metodyczne podej≈õcie`

export async function POST(request: NextRequest) {
  try {
    console.log('üîç [Chat Assistant API] Starting request')

    // Authenticate user
    const supabase = await createAuthenticatedSupabaseClient()
    const user = await getAuthenticatedUser(supabase)

    if (!user) {
      console.error('‚ùå [Chat Assistant API] Unauthorized - no user found')
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    console.log(`‚úÖ [Chat Assistant API] User authenticated: ${user.id}`)

    // Check if OpenAI is configured
    if (!openai) {
      console.error('‚ùå [Chat Assistant API] OpenAI API key not configured')
      return NextResponse.json(
        { error: 'Chat assistant is not configured. Please contact administrator.' },
        { status: 503 }
      )
    }

    // Parse request body
    const body: ChatRequest = await request.json()
    const { message, conversationHistory = [] } = body

    // Validate message
    if (!message || message.trim().length === 0) {
      return NextResponse.json(
        { error: 'Message is required' },
        { status: 400 }
      )
    }

    if (message.length > 500) {
      return NextResponse.json(
        { error: 'Message too long (max 500 characters)' },
        { status: 400 }
      )
    }

    console.log(`üîç [Chat Assistant API] Fetching user context for user: ${user.id}`)

    // Fetch user context
    const context = await fetchChatContext(supabase, user.id)
    const contextString = formatMinimalContextForAI(context)

    console.log(`‚úÖ [Chat Assistant API] Context fetched:
- Tasks today: ${context.tasks.today.length}
- Overdue: ${context.tasks.overdue.length}
- Journal entries: ${context.journal.recent.length}
- Active decisions: ${context.decisions.active.length}`)

    // Detect user intent and prepare structured response if needed
    const userMessageLower = message.toLowerCase()
    let structuredResponse: StructuredResponse | null = null

    // Intent: Emotional support / overwhelmed - COACHING FLOW
    if (
      userMessageLower.includes('nie mogƒô siƒô skupiƒá') ||
      userMessageLower.includes('nie mogƒô siƒô zebraƒá') ||
      userMessageLower.includes('nie mogƒô siƒô ogarnƒÖƒá') ||
      userMessageLower.includes('przyt≈Çacza') ||
      userMessageLower.includes('przyt≈Çoczony') ||
      userMessageLower.includes('przyt≈Çoczona') ||
      userMessageLower.includes('za du≈ºo') ||
      userMessageLower.includes('overwhelmed')
    ) {
      // Check if this is the first message in conversation or user hasn't specified what blocks them
      const isInitialBlockage = conversationHistory.length === 0 || 
        !conversationHistory.some(msg => msg.role === 'assistant' && msg.content.includes('üí≠'))

      if (isInitialBlockage) {
        // Step 1: Ask what blocks them
        return NextResponse.json({
          type: 'text',
          text: 'üí≠ Czy umiesz sprecyzowaƒá, co Ciƒô blokuje?'
        })
      } else {
        // Step 2: Show simplest tasks
        const tasks = await getSimplestTasks(supabase, user.id, 3)
        structuredResponse = {
          type: 'tasks',
          text: `Rozumiem. Masz ${tasks.length} ${tasks.length === 1 ? 'prosty task' : 'proste taski'}:`,
          tasks: tasks,
          footer: 'Kt√≥ry wydaje Ci siƒô naj≈Çatwiejszy?'
        }
      }
    }
    // Intent: Meeting time questions - SMART SCHEDULING FLOW
    else if (
      userMessageLower.includes('spotkanie') ||
      userMessageLower.includes('wolny') ||
      userMessageLower.includes('um√≥wiƒá') ||
      (userMessageLower.includes('kiedy') && (userMessageLower.includes('czas') || userMessageLower.includes('slot')))
    ) {
      // Check if user has specified meeting type and focus level
      const hasFocusLevel = userMessageLower.includes('light') || 
                            userMessageLower.includes('medium') || 
                            userMessageLower.includes('high') ||
                            userMessageLower.includes('check-in') ||
                            userMessageLower.includes('rozmowa') ||
                            userMessageLower.includes('deep work')

      if (!hasFocusLevel && conversationHistory.length === 0) {
        // Step 1: Ask about meeting type
        return NextResponse.json({
          type: 'text',
          text: `Czego dotyczy spotkanie i jakiego wymaga zaanga≈ºowania?
‚Ä¢ Light (rozmowa, check-in)
‚Ä¢ Medium (dyskusja, planning)
‚Ä¢ High (deep work, prezentacja)`
        })
      } else {
        // Step 2: Analyze data and provide recommendations
        const slots = await findFreeTimeSlots(supabase, user.id)
        const calendarStatus = context.calendar?.has_integration 
          ? (context.calendar.events_next_7_days.length > 0 
              ? `üìÖ Masz ${context.calendar.events_next_7_days.length} ${context.calendar.events_next_7_days.length === 1 ? 'spotkanie' : 'spotka≈Ñ'} w tym tygodniu.`
              : 'üìÖ W tym tygodniu nie masz ≈ºadnych spotka≈Ñ w kalendarzu.')
          : 'üìÖ Brak integracji z kalendarzem.'

        if (slots.length > 0) {
          structuredResponse = {
            type: 'meeting_slots',
            text: `${calendarStatus}\n\nAnalizujƒÖc Twoje zadania, proponujƒô:`,
            slots: slots,
            footer: 'Kt√≥ry termin pasuje?'
          }
        } else {
          return NextResponse.json({
            type: 'text',
            text: `${calendarStatus}\n\nW najbli≈ºszym tygodniu wszystkie dni sƒÖ do≈õƒá zajƒôte. Mo≈ºe warto przenie≈õƒá jakie≈õ zadania?`
          })
        }
      }
    }
    // Intent: Tasks today
    else if (
      (userMessageLower.includes('zadania') || userMessageLower.includes('task') || userMessageLower.includes('co')) &&
      (userMessageLower.includes('dzi≈õ') || userMessageLower.includes('dzisiaj') || userMessageLower.includes('today'))
    ) {
      const tasks = await getTodayTasks(supabase, user.id, 5)
      const totalTime = tasks.reduce((sum, t) => sum + t.estimate_min, 0)
      const totalCount = context.tasks.today.length
      structuredResponse = {
        type: 'tasks',
        text: `üéØ Dzi≈õ masz ${totalCount} ${totalCount === 1 ? 'zadanie' : totalCount < 5 ? 'zadania' : 'zada≈Ñ'} (${Math.floor(totalTime / 60)}h ${totalTime % 60}min):`,
        tasks: tasks,
        footer: totalCount > 5 ? `Reszta (${totalCount - 5}) ma ni≈ºszy priorytet.` : 'Od kt√≥rego zaczniesz?'
      }
    }
    // Intent: Overdue tasks
    else if (
      (userMessageLower.includes('przeterminowane') || userMessageLower.includes('overdue') || userMessageLower.includes('sp√≥≈∫nione')) ||
      (userMessageLower.includes('jakie') && userMessageLower.includes('zaleg≈Çe'))
    ) {
      const tasks = await getOverdueTasks(supabase, user.id, 5)
      const totalTime = tasks.reduce((sum, t) => sum + t.estimate_min, 0)
      structuredResponse = {
        type: 'tasks',
        text: `‚ö†Ô∏è ${tasks.length} ${tasks.length === 1 ? 'przeterminowane' : 'przeterminowanych'} (≈ÇƒÖcznie ${Math.floor(totalTime / 60)}h ${totalTime % 60}min):`,
        tasks: tasks,
        footer: 'Kt√≥re jako pierwsze?'
      }
    }

    // If we have structured response, return it immediately without calling OpenAI
    if (structuredResponse) {
      console.log(`‚úÖ [Chat Assistant API] Returning structured response: ${structuredResponse.type}`)
      
      return NextResponse.json(structuredResponse)
    }

    // Build messages for OpenAI
    const messages: ChatMessage[] = [
      {
        role: 'system',
        content: SYSTEM_PROMPT,
      },
      {
        role: 'system',
        content: `DANE U≈ªYTKOWNIKA:\n${contextString}`,
      },
      ...conversationHistory.slice(-6), // Keep last 6 messages (3 pairs) for context
      {
        role: 'user',
        content: message,
      },
    ]

    console.log(`üîç [Chat Assistant API] Calling OpenAI with ${messages.length} messages`)

    // Call OpenAI with streaming
    const stream = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: messages as any,
      temperature: 0.3,
      max_tokens: 150,
      stream: true,
    })

    console.log(`‚úÖ [Chat Assistant API] Streaming response started`)

    // Create SSE (Server-Sent Events) response
    const encoder = new TextEncoder()
    const readable = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of stream) {
            const text = chunk.choices[0]?.delta?.content
            if (text) {
              const data = `data: ${JSON.stringify({ text })}\n\n`
              controller.enqueue(encoder.encode(data))
            }
          }
          controller.enqueue(encoder.encode('data: [DONE]\n\n'))
        } catch (err) {
          console.error('‚ùå [Chat Assistant API] Streaming error:', err)
          controller.error(err)
        } finally {
          controller.close()
        }
      }
    })

    return new Response(readable, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      }
    })
  } catch (error: any) {
    console.error('‚ùå [Chat Assistant API] Error:', error)
    
    // Handle OpenAI API errors
    if (error?.status === 429) {
      return NextResponse.json(
        { error: 'Rate limit exceeded. Please try again later.' },
        { status: 429 }
      )
    }

    if (error?.status === 401) {
      return NextResponse.json(
        { error: 'OpenAI API key invalid or missing' },
        { status: 500 }
      )
    }

    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    )
  }
}
